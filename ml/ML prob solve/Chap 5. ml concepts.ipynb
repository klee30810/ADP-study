{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53823a94",
   "metadata": {},
   "source": [
    "## 5.1 분류와 회귀\n",
    "### 5.1.1 분류\n",
    "- 정해진 범주에 구분해 넣는 작업 : 타겟값이 범주형 데이터\n",
    "\n",
    "### 5.1.2 회귀\n",
    "- 변수 사이 관계 규명, 독립변수와 종속변수 간 관계 모델링 \n",
    "- 독립변수 : 영향을 미치는 변수\n",
    "- 종속변수 : 영향을 받는 변수, 수치형 데이터\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c1afa",
   "metadata": {},
   "source": [
    "### 회귀 평가지표\n",
    "- MAE : 평균 절대 오차 $ \\frac{1}{N}\\sum^N_{i=1}|y_i-\\hat{y}|$\n",
    "- MSE : 평균 제곱 오차 $ \\frac{1}{N}\\sum^N_{i=1}(y_i-\\hat{y})^2$\n",
    "- RMSE : 평균 제곱근 오차 $ \\sqrt{\\frac{1}{N}\\sum^N_{i=1}(y_i-\\hat{y})^2}$\n",
    "- MSLE : Mean Squared Log Error $ \\frac{1}{N}\\sum^N_{i=1}(log(y_i+1)-log(\\hat{y_i}+1))^2 $\n",
    "- RMSLE : Root Mean Squared Log Error $ \\sqrt{\\frac{1}{N}\\sum^N_{i=1}(log(y_i+1)-log(\\hat{y_i}+1))^2} $\n",
    "- $R^2$ : 결정계수,  $ \\frac{(예측 타깃값의 분산)}{(실제 타깃값의 분산)} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374933ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5385\t, MSE: 0.6923\t, RMSE: 0.8321\n",
      "MSLE: 0.0296\t, RMSLE: 0.1721\t, R2: 0.8617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "\n",
    "true = np.array([1,2,3,2,3,5,4,6,5,6,7,8,8,])\n",
    "preds = np.array([1,1,2,2,3,4,4,5,5,7,7,6,8,])\n",
    "\n",
    "mae = mean_absolute_error(true, preds)\n",
    "mse = mean_squared_error(true, preds)\n",
    "rmse = np.sqrt(mse)\n",
    "msle = mean_squared_log_error(true, preds)\n",
    "rmsle = np.sqrt(msle)\n",
    "r2 = r2_score(true, preds)\n",
    "\n",
    "print(f'MAE: {mae:.4f}\\t, MSE: {mse:.4f}\\t, RMSE: {rmse:.4f}')\n",
    "print(f'MSLE: {msle:.4f}\\t, RMSLE: {rmsle:.4f}\\t, R2: {r2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d194770",
   "metadata": {},
   "source": [
    "## 5.2 분류 평가지표\n",
    "### 5.2.1 오차행렬\n",
    "- 정확도 : 실제값과 예측값이 얼마나 일치되는지 비율. 전체 값 중 TP, TN이 차지하는 비율 $\\frac{TP+TN}{TP+FP+FN+TN} $\n",
    "- 정밀도 : 양성 예측의 정확도, 음성을 양성으로 잘못 판단하면 문제가 발생하는 경우(스팸 메일) $\\frac{TP}{TP+FP}$\n",
    "- 재현율 : 실제 양성값 중 양성으로 잘 예측한 값의 비율. 양성을 음성으로 판단하면 잘못되는 문제 (암진단) $\\frac{TP}{TP+FN}$\n",
    "- F1 점수 : 정밀도와 재현율의 조화평균 $F1=\\frac{2}{\\frac{1}{precision}+\\frac{1}{recall}=2\\times\\frac{precision\\times recall}{precision + recall}}$\n",
    "\n",
    "### 5.2.2 로그 손실\n",
    "- 분류문제에서 타깃값을 확률로 예측할 때 기본, 작을 수록 좋다\n",
    "$$log\\ loss=-\\frac{1}{N}\\sum^N_{i=1}(y_ilog(\\hat{y_i})+(1-y_i)log(1-\\hat{y_i}))$$\n",
    "\n",
    "### 5.2.3 ROC 곡선과 AUC\n",
    "- ROC 곡선 : 참 양성비율 (TPR, 재현율)에 대한 거짓양성 비율(FPR, 1-TNR[=$\\frac{TN}{FP+TN}$])\n",
    "- AUC : ROC 곡선 아래 면적, 예측값이 확률인 분류문제에 사용\n",
    "* 타깃값(이산값)으로 예측 시 분류 평가 : F1\n",
    "* 타깃 확률 예측시 : 로그 손실, AUC\n",
    "- 예측 확률값의 대소 순서가 같다면 AUC도 같음, 대소 순서가 같더라도 확률값이 다르면 로그손실 점수도 달라짐\n",
    "- 양성 타깃값이 부족하면, 양성을 얼마나 잘 예측했는지가 AUC에 양향ㅇ르 많이 줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e24c746",
   "metadata": {},
   "source": [
    "## 5.3. 데이터 인코딩\n",
    "- 범주형 데이터의 숫자형태로 바꾸는 작업\n",
    "\n",
    "### 5.3.1 레이블 인코딩\n",
    "- 범주형 데이터를 숫자로 일대일 매핑\n",
    "- 머신러닝 모델은 서로 가까운 숫자를 비슷한 데이터로 판단하므로, 순서가 의미없는 명목형 데이터를 레이블 인코딩하면 성능이 떨어질 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad191b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1 0 2 1 1 3]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "fruits = ['사과', '블루베리', '바나나', '귤', '블루베리', '바나나', '바나나', '사과']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "fruits_label_encoded = label_encoder.fit_transform(fruits)\n",
    "\n",
    "print(fruits_label_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0003d213",
   "metadata": {},
   "source": [
    "### 5.3.2 원-핫 인코딩\n",
    "- 여러 값 중, 하나만 인코딩. 지나치게 열 개수가 많아짐\n",
    "- 고유값이 너무 많을 경우\n",
    "1) 비슷한 고유값 끼리 그룹화 : 해당 명목형 피쳐의 고유값 개수 감소\n",
    "2) 빈도가 낮은 고유값 기타 처리 : 비슷한 효과\n",
    "3) 다른 인코딩 적용 : 타깃 인코딩, 프리퀀시 인코딩\n",
    "\n",
    "- 문자열 데이터에 바로 원-핫 인코딩을 적용할 수 없어, 먼저 레이블 인코딩으로 숫자형 데이터로 변환\n",
    "- 결과가 0이 대부분인 희소행렬이라, 메모리 낭비가 심각, CSR 형태로 돌려줌 => toarray()를 사용하여 일반 더비로 변화\n",
    "- pd.get_dummies를 쓰면 숫자형을 바꾸지 않아도 되서 훨씬 편리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e822723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "fruits = ['사과', '블루베리', '바나나', '귤', '블루베리', '바나나', '바나나', '사과']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "fruits_label_encoded = label_encoder.fit_transform(fruits)\n",
    "fruits_onehot_encoded = onehot_encoder.fit_transform(fruits_label_encoded.reshape(-1,1))\n",
    "\n",
    "print(fruits_onehot_encoded.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0867e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>귤</th>\n",
       "      <th>바나나</th>\n",
       "      <th>블루베리</th>\n",
       "      <th>사과</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   귤  바나나  블루베리  사과\n",
       "0  0    0     0   1\n",
       "1  0    0     1   0\n",
       "2  0    1     0   0\n",
       "3  1    0     0   0\n",
       "4  0    0     1   0\n",
       "5  0    1     0   0\n",
       "6  0    1     0   0\n",
       "7  0    0     0   1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.get_dummies(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668c2fe",
   "metadata": {},
   "source": [
    "## 5.4 피쳐 스케일링\n",
    "- 서로 다른 피쳐값의 볌위가 일치하도록 조정하는 작업 (트리 기반 모델들은 데이터 크기보다 대소관계 영향을 받으므로 스케일링 필요 없음)\n",
    "\n",
    "### 5.4.1 min-max wjdrbghk\n",
    "- 피쳐 값의 범위를 0~1로 조정 $$ x_{encoded} = \\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
    "- 이상치가 너무 크거나 작을 때는 좋지 않은 결과 : 이상치는 0 또는 1이 되겠으나, 나머지 값들은 아주 미세한 차이로 좁은 구간에 몰리므로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a011dbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66666667, 1.        ],\n",
       "       [0.        , 0.        ],\n",
       "       [1.        , 0.25      ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "height_weight_dict = {'height':[1.7, 1.5, 1.8], 'weight':[75,55,60]}\n",
    "df = pd.DataFrame(height_weight_dict, index=['광일', '혜성', '덕수'])\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(df)\n",
    "df_scaled = scaler.transform(df)\n",
    "\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a6b79",
   "metadata": {},
   "source": [
    "### 5.4.2 표준화\n",
    "- 평균 0, 분산 1 되도록 피쳐값 조정 : 상,하한을 따로 정해야하는 경우가 아니라면 적용 가능 $x_{encoded}=\\frac{x-\\hat{x}}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68656daa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.26726124,  1.37281295],\n",
       "       [-1.33630621, -0.98058068],\n",
       "       [ 1.06904497, -0.39223227]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34229f",
   "metadata": {},
   "source": [
    "## 5.5 교차검증\n",
    "- 과대적합 해소 & 제출전 모델 성능 가늠\n",
    "\n",
    "### 5.5.1 K 폴드 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4340a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: [0 2 3 4 5 7 8 9], valid data: [1 6]\n",
      "train data: [0 1 3 4 5 6 8 9], valid data: [2 7]\n",
      "train data: [0 1 2 4 5 6 7 8], valid data: [3 9]\n",
      "train data: [0 1 2 3 5 6 7 9], valid data: [4 8]\n",
      "train data: [1 2 3 4 6 7 8 9], valid data: [0 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "data = np.array([0,1,2,3,4,5,6,7,8,9])\n",
    "folds = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train_idx, valid_idx in folds.split(data):\n",
    "    print(f\"train data: {data[train_idx]}, valid data: {data[valid_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83498f56",
   "metadata": {},
   "source": [
    "### 5.5.2 층화 K폴드 교차 검증\n",
    "- 타깃값이 골고루 분포되게 폴드를 나누는 방법. 타깃값이 불균형하게 분포되어 있는 경우 사용(특정 타깃 값이 다른 타깃 값 보다 굉장히 적은 경우)\n",
    "- 분류문제만 사용 : 연속 값은 균일한 비율로 나누는게 불가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39002376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 \n",
      "target ['spam' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
      " 'normal' 'normal']\n",
      "fold 2 \n",
      "target ['spam' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
      " 'normal' 'normal']\n",
      "fold 3 \n",
      "target ['spam' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
      " 'normal' 'normal']\n",
      "fold 4 \n",
      "target ['spam' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
      " 'normal' 'normal']\n",
      "fold 5 \n",
      "target ['spam' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal' 'normal'\n",
      " 'normal' 'normal']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array(range(50))\n",
    "y = np.array(['spam']*5 + ['normal']*45)\n",
    "\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X,y)):\n",
    "    print(f\"fold {idx+1} \\ntarget {y[valid_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7c6d5",
   "metadata": {},
   "source": [
    "## 5.6 주요 머신러닝 모델\n",
    "### 5.6.1 선형 회귀모델\n",
    "- 훈련 데이터에 잘 맞는 모델 파라미터, 회귀계수 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ba43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w0 : [5.09772262], w1 : [[1.9808382]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fbfec35d810>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "w0 = 5; w1 = 2;\n",
    "noise = np.random.randn(100,1)\n",
    "\n",
    "x = 4 * np.random.rand(100,1)\n",
    "y = w1*x + w0 + noise\n",
    "\n",
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(x,y)\n",
    "\n",
    "print(f'w0 : {linear_reg_model.intercept_}, w1 : {linear_reg_model.coef_}')\n",
    "\n",
    "y_pred = linear_reg_model.predict(x)\n",
    "\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb182cf0",
   "metadata": {},
   "source": [
    "### 5.6.2 로지스틱 회귀 모델\n",
    "- 시그모이드 함수를 활용해 타깃값에 포함 될 확률 예측 $\\frac{1}{1+e^{-x}}$\n",
    "\n",
    "### 5.6.3 결정 트리\n",
    "- 스무고개\n",
    "- 분할 방식 : 이전 분할 결과에 이후 결과가 영향 받음\n",
    "- 불순도 : 한 범주 안에 서로 다른 데이터가 얼마나 섞여 있는가\n",
    "- 엔트로피 : 불확실한 정도, (1-엔트로피 = 정보이득) / 지니 불순도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77a16d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9298\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data['data'], cancer_data['target'], stratify=cancer_data['target'], test_size=0.4, random_state=42)\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "accuracy = decision_tree.score(X_test, y_test)\n",
    "\n",
    "print(np.round(accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bdcf22",
   "metadata": {},
   "source": [
    "### 5.6.4 앙상블 학습\n",
    "- 보팅 : 개별 결과 종합.\n",
    "- 하드 보팅 : 다수결 투표 방식\n",
    "- 소프트 보팅 : 개별 예측 확률의 평균 => 대체로 나은 성능\n",
    "- 배깅 : 개별 모델로 예측한 결과를 결합, 개별 모델이 서로 다른 샘플링 데이터 활용\n",
    "- 부스팅 : 가중치를 활용해 분류 성능이 약한 모델 강하게 만듬. 잘못 예측한 데이터에 가중치를 부여하여 더 집중해 훈련\n",
    "\n",
    "### 5.6.5 랜덤 포레스트\n",
    "- 결정트리를 배깅 방식으로 결합한 모델\n",
    "- n_estimator(결정트리 개수), criterion, max_depth(트리 최대 깊이), min_samples_split(노드 분할을 위한 최소 데이터 개수), min_samples_leaf(말단 노드가 되기 위한 최소 데이터 개수), max_features(분할에 사용할 피쳐 개수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10ae9b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9385964912280702"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data['data'], cancer_data['target'], stratify=cancer_data['target'], test_size=0.4, random_state=42)\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "accuracy = random_forest.score(X_test, y_test)\n",
    "\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98421e46",
   "metadata": {},
   "source": [
    "### 5.6.6. XGBoost\n",
    "- 결정트리 직렬로 배치, 부스팅 -> 직전 트리가 예측한 값을 다음 트리가 활용해 예측값 조금씩 수정\n",
    "- 파이썬 래퍼 XGBoost를 사용하려면 별도 데이터 셋을 생성 : 모델 훈련 및 예측 부분이 더 명시적\n",
    "- booster : gbtree, dart(dropout 적용 gbtree)\n",
    "- objective : 'reg:squarederror'(회귀), 'binary:logistic'(이진분류), 'multi:softmax'(다중 분류), 'multi:softprob'(확률값 다중분류)\n",
    "- eta (learning rate) : 일반 0.0001~0.1\n",
    "- max_depth : 개별 트리 최대 깊이, 3~10\n",
    "- subsample : 개별 트리 훈련 시, 데이터 샘플링 비율, 0.6~1\n",
    "- colsample_bytree : 개별 트리 훈련 시 피쳐 샘플링 비율, 0.6~1\n",
    "- alpha (reg_alpha) : L1 규제 조정값\n",
    "- lambda (reg_lambda) : L2  규제 조정값\n",
    "- gamma (min_split_loss) : 말단 노드 분할하기 위한 최소 손실 감소 값\n",
    "- min_child_weight : 과대적합 방지 위한 값\n",
    "- scale_pos_weight : 불균형 데이터 가중치 조정 값 => (음성 타겟 # / 양성 타겟 #)로 설정\n",
    "- random_state\n",
    "- train 메서드 기능 : num_boost_round(부스팅 반복 횟수, 늘리면 learning_rate 줄여야 함) / early_stopping_rounds(조기종료 조건, 해당 조건 동안 성능 좋아지지 않으면 중단. eta가 작으면 크게 설정. 학습률이 작으면 그만큼 가중치가 천천히 갱신되므로 조기종료 조건이 커야 함) / verbose_eval (중간 성능 출력값이 너무 많아지는 것 방지)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5953864",
   "metadata": {},
   "source": [
    "### 5.6.7 LightGBM\n",
    "- 말단 노드 중심으로 예측 오류를 최소화하게끔 분할. 다른 모델처럼 균형을 유지할 필요가 없어서 추가 연산도 필요 없음. 하지만 데이터 개수가 적을 때에는 과대적합되기 쉬움\n",
    "- boosting_type : gbdt, dart, goss, rf\n",
    "- objective : regression, binary, multiclass\n",
    "- learning_rate (eta) : 학습률\n",
    "- num_leaves : 개별 트리가 가질 수 있는 최대 말단 노드 개수, 값이 클 수록 과대적합 가능\n",
    "- max_depth : 개별트리 깊이, 말단 노드 중심 분할이므로 크게 잡는게 좋음\n",
    "- bagging_fraction (subsample) : 개별 트리 훈련시 사용할 데이터 샘플링 비율, bagging_freq 파라미터를 0이 아닌 값으로 설정 해야\n",
    "- feature_fraction (colsample_bytree) : 개별 트리 훈련 시 피쳐 샘플링 비율\n",
    "- lambda_l1 (reg_alpha) : L1 규제 조정값\n",
    "- lambda_l2 (reg_lambda) : L2 규제 조정값\n",
    "- min_child_samples : 말단 노드가 되기 위해 필요한 최소 데이터 갯수\n",
    "- min_child_weight : 클수록 과대적합 방지\n",
    "- bagging_freq (subsample_freq) : 배깅 수행 빈도, 몇 번의 이터레이션 마다 배깅 수행할지 결정, 1 전달 시 매 이터레이션 마다 트리가 새로운 샘플링 데이터로 학습\n",
    "- force_row_wise : 메모리 충분하지 않을 때 효율을 높임\n",
    "- train 메소드 기능 : num_boost_round, early_stopping_rounds(학습률이 작으면 early_stopping_rounds 크게 설정)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82a6e0",
   "metadata": {},
   "source": [
    "## 5.7 하이퍼파라미터 최적화\n",
    "### 5.7.1 그리드 서치\n",
    "- 모든 경우의 수를 탐색\n",
    "\n",
    "### 5.7.2 랜덤 서치\n",
    "- 무작위 탐색\n",
    "\n",
    "### 5.7.3 베이지안 최적화\n",
    "- 사전정보를 바탕으로 최적 하이퍼파라미터 값을 확률적으로 추정\n",
    "- bayes_opt 패키지 이용\n",
    "- 탐색범위 설정 -> 평가지표 계산함수 정의 -> BayesianOptimization 객체 생성 -> 베이지안 최적화 수행"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adp",
   "language": "python",
   "name": "adp_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
